{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Короткий пайплайн:\n",
    "- использовать модель BERTа для создания эмбеддингов для датасета SST (это датасет с предложениями-отзывами о фильмах и оценкой: 1 - отзыв с положительной тональностью, а 0 - отзыв с отрицательной тональностью). Результат этой модели (эмбеддинг предложения) передать на вход следующей модели. Воспользуюсь предобученной моделью BERTa. В качества выхода модели BERT использую вычисления первой позиции - [CLS] токена\n",
    "- создать классификатор, основанный на логистической регрессии для классификации позитивная или негативная тональность была в обработанном бертом предложении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataSet():\n",
    "    df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаю предобученную модель BERT и токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#токинезация. Разбиваю предложения в нужный для входа в BERT формат\n",
    "def do_tokenization(df):\n",
    "    tokenized = df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#запомню размер максимального числа токенов в предложениях\n",
    "max_len = 0\n",
    "for i in do_tokenization(df).values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#добавление пиддинга. После токинезации число токенов от разных предложений могло получиться разным, а матрица нам нужна ровная\n",
    "def add_padding(tokenized):\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#добавление масок к токенам\n",
    "def att_mask(padded):\n",
    "    masked = np.where(padded != 0, 1, 0)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepared_dataSet(df):\n",
    "    prepared_df = add_padding(do_tokenization(df))\n",
    "    return prepared_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пропускаю через BERT, чтобы найти last_hidden_states\n",
    "prepared_df = prepared_dataSet(df)\n",
    "inputs = torch.LongTensor(prepared_df)  \n",
    "attention_mask = torch.tensor(att_mask(prepared_df))\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(inputs, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нам нужен только первый токен каждого предложения. Способ, которым BERT выполняет классификацию предложений, заключается в том,\n",
    "#что он добавляет токен под названием «[CLS]« (для классификации) в начале каждого предложения\n",
    "X = last_hidden_states[0][:,0,:].numpy()\n",
    "y = df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использую логистическую регрессию, как классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#спличу получившийся массив на тестовую и тренировочную выборки\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksandr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8473988439306358"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg_model = LogisticRegression()\n",
    "logReg_model.fit(train_X, train_y)\n",
    "logReg_model.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверю работу модели на своих предложениях. предложения абсолютно случайные ;-)\n",
    "\n",
    "good_sentences = [\"Sasha Khvorov is the greatest guy I have ever met\", \"This project is awesome and I will prove it\"]\n",
    "bad_sentences = [\"I will be so dissapointed if I fail this test task\", \"other projects sucks comparing to this one\"]\n",
    "test_sentences = pd.DataFrame(good_sentences + bad_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пропускаю через BERT, чтобы найти last_hidden_states для тестовых предложений\n",
    "prepared_df_test = prepared_dataSet(test_sentences)\n",
    "inputs_test = torch.LongTensor(prepared_df_test)  \n",
    "attention_mask_test = torch.tensor(att_mask(prepared_df_test))\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_test = model(inputs_test, attention_mask=attention_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрю на вектор после классификатора:\n",
    "X2 = last_hidden_states_test[0][:,0,:].numpy()\n",
    "logReg_model.predict(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель правильно отнесла первые два предложения к позитивной тональности, а вторые к негативной!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
